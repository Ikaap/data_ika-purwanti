[2024-04-16T12:29:07.555+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-04-16T12:29:07.879+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: exploration_dag_v1.create_table_task scheduled__2024-04-14T00:00:00+00:00 [queued]>
[2024-04-16T12:29:07.937+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: exploration_dag_v1.create_table_task scheduled__2024-04-14T00:00:00+00:00 [queued]>
[2024-04-16T12:29:07.946+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 6
[2024-04-16T12:29:08.053+0000] {taskinstance.py:2327} INFO - Executing <Task(PostgresOperator): create_table_task> on 2024-04-14 00:00:00+00:00
[2024-04-16T12:29:08.068+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=71) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-04-16T12:29:08.075+0000] {standard_task_runner.py:63} INFO - Started process 81 to run task
[2024-04-16T12:29:08.078+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'exploration_dag_v1', 'create_table_task', 'scheduled__2024-04-14T00:00:00+00:00', '--job-id', '374', '--raw', '--subdir', 'DAGS_FOLDER/exploration_dag.py', '--cfg-path', '/tmp/tmpm4xby1f8']
[2024-04-16T12:29:08.084+0000] {standard_task_runner.py:91} INFO - Job 374: Subtask create_table_task
[2024-04-16T12:29:08.258+0000] {task_command.py:426} INFO - Running <TaskInstance: exploration_dag_v1.create_table_task scheduled__2024-04-14T00:00:00+00:00 [running]> on host 80febf28041c
[2024-04-16T12:29:08.511+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='ika' AIRFLOW_CTX_DAG_ID='exploration_dag_v1' AIRFLOW_CTX_TASK_ID='create_table_task' AIRFLOW_CTX_EXECUTION_DATE='2024-04-14T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-04-14T00:00:00+00:00'
[2024-04-16T12:29:08.513+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-04-16T12:29:08.597+0000] {sql.py:276} INFO - Executing: CREATE TABLE IF NOT EXISTS fruits(
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    calories FLOAT NOT NULL,
    fat FLOAT NOT NULL,
    sugar FLOAT NOT NULL,
    carbohydrates FLOAT NOT NULL,
    protein FLOAT NOT NULL
);
[2024-04-16T12:29:08.629+0000] {base.py:84} INFO - Using connection ID 'my_postgres' for task execution.
[2024-04-16T12:29:08.800+0000] {base.py:84} INFO - Using connection ID 'my_postgres' for task execution.
[2024-04-16T12:29:08.821+0000] {sql.py:457} INFO - Running statement: CREATE TABLE IF NOT EXISTS fruits(
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    calories FLOAT NOT NULL,
    fat FLOAT NOT NULL,
    sugar FLOAT NOT NULL,
    carbohydrates FLOAT NOT NULL,
    protein FLOAT NOT NULL
);, parameters: None
[2024-04-16T12:29:08.836+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/providers/common/sql/hooks/sql.py:407: AirflowProviderDeprecationWarning: Call to deprecated method _make_common_data_structure. (The `_make_serializable` method is deprecated and support will be removed in a future version of the common.sql provider. Please update the DbApiHook's provider to a version based on common.sql >= 1.9.1.)
  result = self._make_common_data_structure(handler(cur))

[2024-04-16T12:29:08.843+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-04-16T12:29:08.864+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=exploration_dag_v1, task_id=create_table_task, execution_date=20240414T000000, start_date=20240416T122907, end_date=20240416T122908
[2024-04-16T12:29:08.964+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-04-16T12:29:09.011+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/models/baseoperator.py:1296: AirflowProviderDeprecationWarning: Call to deprecated class PostgresOperator. (Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`.Also, you can provide `hook_params={'schema': <database>}`.)
  result = cls.__new__(cls)

[2024-04-16T12:29:09.061+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-16T12:29:09.070+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
